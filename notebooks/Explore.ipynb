{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from nltk import tokenize\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stopwords = [\n",
    "    'the','and','to','of','was','with','on','in','for','no','name',\n",
    "    'is','he','or','at','as','one','she','am','you','his',\n",
    "    'your','were','by','pt','not','her','be','this','are','there',\n",
    "    'had','date','from','first','an','that','have','but','has','please','which',\n",
    "    'namepattern','seen','every','fax', 'home', 'telephone', 'given', 'after', \n",
    "    'also','will', 'un', 'up', 'well', 'time', 'any']\n",
    "token_space = tokenize.WhitespaceTokenizer()\n",
    "\n",
    "def counter(text, column_text, quantity, stopwords):\n",
    "    all_words = ' '.join([text for text in text[column_text].astype('str')])\n",
    "    token_phrase = token_space.tokenize(all_words)\n",
    "    frequency = nltk.FreqDist(token_phrase) \n",
    "    df_frequency = pd.DataFrame({\"Word\": list(frequency.keys()), \"Frequency\": list(frequency.values())}) \n",
    "    df_frequency = df_frequency[~df_frequency['Word'].isin(stopwords)].reset_index()\n",
    "    df_frequency = df_frequency.nlargest(columns = \"Frequency\", n = quantity)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    ax = sns.barplot(data = df_frequency, x = \"Word\", y = \"Frequency\", palette=\"deep\")\n",
    "    ax.set(ylabel = \"Count\")\n",
    "    plt.xticks(rotation='horizontal')\n",
    "    plt.show()\n",
    "\n",
    "def normalize(text):\n",
    "    text = text.str.lower()\n",
    "    text = text.str.replace(r'[^A-Za-z0-9]+', ' ', regex=True)\n",
    "    text = text.str.replace('\\s{2,}', ' ', regex=False)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/raw/news.csv')\n",
    "df['label'] = (df['label'] == 'FAKE').astype('int')\n",
    "df['titletext'] = df['title'] + \". \" + df['text']\n",
    "df = df.reindex(columns=['label', 'titletext'])\n",
    "df['titletext'] = normalize(df['titletext'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter(df[df['label'] == 0], 'titletext', 30, stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter(df[df['label'] == 1], 'titletext', 30, stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "251bb9106bb289545a2afd1750c61dee62351dc92ad407674766b8e67b5d9637"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
